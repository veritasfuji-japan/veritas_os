#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
VERITAS Log Analyzer (Doctor Dashboard + CSV + Graph)
"""

import argparse
import csv
import json
import re
import sys
from pathlib import Path
from datetime import datetime
from collections import Counter, defaultdict

# ========================================
#  ãƒ‘ã‚¹è¨­å®šï¼ˆveritas_os ã‹ã‚‰ã®ç›¸å¯¾ï¼‰
# ========================================

BASE_DIR = Path(__file__).resolve().parents[1]          # .../veritas_os
LOG_DIR  = BASE_DIR / "scripts" / "logs"                # .../veritas_os/scripts/logs
REPORT_JSON = LOG_DIR / "doctor_report.json"            # Web Doctor ç”¨

# decide_YYYYMMDD_HHMMSS.json ã¾ãŸã¯ decide_YYYYMMDD_HHMMSS_123.json ã«å¯¾å¿œ
FNAME_RE = re.compile(r"decide_(\d{8})_(\d{6})(?:_\d+)?\.json")


# ========================================
#  1) ãƒ­ã‚°åã‹ã‚‰ timestamp ã‚’æŠ½å‡º
# ========================================
def parse_ts_from_name(name: str):
    m = FNAME_RE.search(name)
    if not m:
        return None
    ymd, hms = m.groups()
    try:
        return datetime.strptime(ymd + hms, "%Y%m%d%H%M%S")
    except Exception:
        return None


# ========================================
#  2) JSONã‚»ãƒ¼ãƒ•å–å¾—
# ========================================
def safe_get(d, *path, default=None):
    cur = d
    for key in path:
        if isinstance(cur, dict) and key in cur:
            cur = cur[key]
        else:
            return default
    return cur


# ========================================
#  3) 1ãƒ¬ã‚³ãƒ¼ãƒ‰æŠ½å‡º
# ========================================
def extract_one(record: dict) -> dict:
    status, reason, text = None, None, None

    # decide() ç³»
    if "decision" in record:
        status = safe_get(record, "decision", "chosen")
        reason = safe_get(record, "decision", "reason")

    # fuji ç³»
    elif "fuji" in record:
        status = safe_get(record, "fuji", "status")
        reasons = safe_get(record, "fuji", "reasons")
        if isinstance(reasons, list) and reasons:
            reason = reasons[0]

    # ãã®ä»–ã®å‹
    elif "result" in record:
        status = safe_get(record, "result", "status")

    text = (
        safe_get(record, "meta", "echo", "content")
        or safe_get(record, "context", "query")
        or safe_get(record, "request", "content")
        or safe_get(record, "input")
    )

    return {
        "status": (status or "").lower() or None,
        "reason": reason,
        "text": text,
    }


# ========================================
#  4) ãƒ­ã‚°èª­ã¿è¾¼ã¿
# ========================================
def load_logs() -> list[dict]:
    if not LOG_DIR.exists():
        print(f"[!] ãƒ­ã‚°ãƒ•ã‚©ãƒ«ãƒ€ãŒã‚ã‚Šã¾ã›ã‚“: {LOG_DIR}")
        sys.exit(1)

    rows = []
    for p in sorted(LOG_DIR.glob("decide_*.json")):
        try:
            with p.open("r", encoding="utf-8") as f:
                data = json.load(f)
            info = extract_one(data)
            info["file"] = p.name
            info["timestamp"] = parse_ts_from_name(p.name)
            rows.append(info)
        except Exception as e:
            print(f"[warn] èª­ã¿è¾¼ã¿å¤±æ•— {p.name}: {e}")

    return rows


# ========================================
#  5) é›†è¨ˆï¼ˆã‚³ãƒ³ã‚½ãƒ¼ãƒ« + Web Doctor JSONï¼‰
# ========================================
def summarize(rows: list[dict]) -> dict:
    if not rows:
        print("âš ï¸ ãƒ­ã‚°ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãš /v1/decide ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return {"count": 0, "items": []}

    total = len(rows)
    by_status = Counter(r.get("status") or "unknown" for r in rows)
    by_reason = Counter((r.get("reason") or "n/a") for r in rows)

    print("\n=== â‘  ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥é›†è¨ˆ ===")
    for status, cnt in by_status.most_common():
        pct = 100.0 * cnt / total
        print(f"- {status:8s}: {cnt:4d} ({pct:5.1f}%)")
    print(f"- total    : {total:4d}")

    print("\n=== â‘¡ ç†ç”±ãƒˆãƒƒãƒ—10 ===")
    for reason, cnt in by_reason.most_common(10):
        print(f"- {reason}: {cnt}")

    print("\n=== â‘¢ ç›´è¿‘5ä»¶ ===")
    latest = sorted(
        [r for r in rows if r.get("timestamp")],
        key=lambda x: x["timestamp"],
        reverse=True
    )[:5]

    for r in latest:
        ts = r["timestamp"].strftime("%Y-%m-%d %H:%M:%S")
        status = r.get("status") or "unknown"
        reason = r.get("reason") or "-"
        text = (r.get("text") or "").replace("\n", " ")
        if len(text) > 60:
            text = text[:57] + "..."
        print(f"- {ts} | {status:6s} | {reason:20s} | {text}")

    # Web Doctor ç”¨
    latest_for_json = [
        {
            "time": r["timestamp"].strftime("%Y-%m-%d %H:%M:%S"),
            "status": r.get("status") or "unknown",
            "reason": r.get("reason") or "-",
            "text": r.get("text") or "",
        }
        for r in latest
    ]

    return {
        "count": total,
        "by_status": dict(by_status),
        "by_reason_top10": dict(by_reason.most_common(10)),
        "latest": latest_for_json,
    }


# ========================================
#  6) CSVæ›¸ãå‡ºã—
# ========================================
def export_csv(rows: list[dict], out_path: Path) -> None:
    out_path.parent.mkdir(parents=True, exist_ok=True)

    with out_path.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(["timestamp", "status", "reason", "text", "file"])

        for r in sorted(rows, key=lambda x: x.get("timestamp") or datetime.min):
            ts = r["timestamp"].strftime("%Y-%m-%d %H:%M:%S") if r.get("timestamp") else ""
            w.writerow([
                ts,
                r.get("status") or "",
                r.get("reason") or "",
                r.get("text") or "",
                r.get("file") or "",
            ])

    print(f"\nğŸ“„ CSVã‚’æ›¸ãå‡ºã—ã¾ã—ãŸ: {out_path}")


# ========================================
#  7) ã‚°ãƒ©ãƒ•ç”Ÿæˆ
# ========================================
def make_graphs(rows: list[dict], out_dir: Path) -> list[Path]:
    out_dir.mkdir(parents=True, exist_ok=True)
    paths = []

    import matplotlib.pyplot as plt

    # === 1) ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥ä»¶æ•° ===
    by_status = Counter(r.get("status") or "unknown" for r in rows)
    labels, values = zip(*sorted(by_status.items()))

    plt.figure()
    plt.bar(labels, values)
    plt.title("Decision count by status")
    plt.xlabel("status")
    plt.ylabel("count")
    p1 = out_dir / "status_counts.png"
    plt.savefig(p1, bbox_inches="tight")
    plt.close()
    paths.append(p1)

    # === 2) æ—¥åˆ¥ allowç‡ ===
    by_day_total = defaultdict(int)
    by_day_allow = defaultdict(int)

    for r in rows:
        if not r.get("timestamp"):
            continue
        day = r["timestamp"].strftime("%Y-%m-%d")
        by_day_total[day] += 1
        if (r.get("status") or "").lower() == "allow":
            by_day_allow[day] += 1

    if by_day_total:
        days = sorted(by_day_total.keys())
        rates = [(by_day_allow[d] / by_day_total[d]) * 100.0 for d in days]

        plt.figure()
        plt.plot(days, rates, marker="o")
        plt.title("Allow rate by day")
        plt.xlabel("date")
        plt.ylabel("allow %")
        plt.xticks(rotation=30, ha="right")
        p2 = out_dir / "allow_rate_daily.png"
        plt.savefig(p2, bbox_inches="tight")
        plt.close()
        paths.append(p2)

    return paths


# ========================================
#  8) ãƒ¡ã‚¤ãƒ³
# ========================================
def build_parser():
    p = argparse.ArgumentParser(description="VERITAS ãƒ­ã‚°è§£æãƒ„ãƒ¼ãƒ«")
    p.add_argument("--graph", action="store_true", help="PNGã‚°ãƒ©ãƒ•ç”Ÿæˆ")
    p.add_argument("--csv", action="store_true", help="CSVå‡ºåŠ›")
    return p


def main(argv=None):
    args = build_parser().parse_args(argv)

    rows = load_logs()
    summary = summarize(rows)

    # doctor_report.json (Web Doctorç”¨)
    with REPORT_JSON.open("w", encoding="utf-8") as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ§¾ doctor_report.json ã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {REPORT_JSON}")

    if args.csv or not args.graph:
        export_csv(rows, LOG_DIR / "summary.csv")

    if args.graph:
        imgs = make_graphs(rows, LOG_DIR)
        print("\nğŸ–¼ ç”Ÿæˆã—ãŸã‚°ãƒ©ãƒ•:")
        for p in imgs:
            print(f"- {p}")

    print("\nâœ… è§£æãŒå®Œäº†ã—ã¾ã—ãŸã€‚")


if __name__ == "__main__":
    main()

