# VERITAS OS ‚Äî Proto-AGI Decision OS / Public API

> This README is for the `veritas_os/` directory inside the `veritas_clean_test2` repository.  
> Clone `veritas_clean_test2` first, then use the `veritas_os` folder as the library / API server.

---

## TL;DR

- **VERITAS OS = a framework that wraps an LLM as a Proto-AGI ‚ÄúDecision OS‚Äù**, rather than calling the LLM directly.
- `/v1/decide` runs a **full decision loop in one shot**:
  - option generation ‚Üí evidence collection ‚Üí critique ‚Üí debate ‚Üí safety gate (FUJI) ‚Üí immutable trust log.
- Designed to be called from **OpenAPI 3.1 + Swagger Studio**, talking to a local `uvicorn` server.
- Ships with **MemoryOS / WorldModel / ValueCore / FUJI Gate / Doctor Dashboard** as one coherent ‚ÄúAGI skeleton‚Äù.
- Goal: an **experimental platform for using LLMs as safe, reproducible and auditable proto-AGI decision engines.**

---

## What is VERITAS OS?

Instead of ‚Äújust calling the LLM API‚Äù (e.g. OpenAI), VERITAS OS wraps it as:

> **‚ÄúAn OS that runs the LLM as a safe, consistent and inspectable decision engine.‚Äù**

It exposes a **Proto-AGI framework / Decision OS** via a public API described by an **OpenAPI 3.1 schema** (for Swagger Studio / Editor):

- `/v1/decide` ‚Äì full decision loop (ValueCore / FUJI / Memory / WorldModel / ReasonOS)
- `/v1/fuji/validate` ‚Äì safety & ethics validation for a single candidate action
- `/v1/memory/*` ‚Äì persistent memory put/get
- `/v1/logs/trust/{request_id}` ‚Äì immutable trust-log retrieval

All endpoints are protected with **X-API-Key** authentication.

---

## üîß What makes VERITAS OS different?

1. **Decision-first design**

   - You don‚Äôt call the LLM directly ‚Äì you call `/v1/decide`.
   - Every call returns a full decision structure:
     `chosen / alternatives / evidence / critique / debate / fuji / trust_log`.

2. **Safety & Trust as first-class APIs**

   - `/v1/fuji/validate` lets you run **only** the safety / ethics gate, independent of the main decision loop.
   - `/v1/logs/trust/{request_id}` returns a **chained trust log** so decisions can be audited later.

3. **A unified ‚ÄúProto-AGI skeleton‚Äù (Memory / World / ValueCore)**

   - MemoryOS, WorldModel and ValueCore are wired into the loop.
   - Their state is surfaced both in the `DecideResponse` and in the Doctor Dashboard.

---

## üí° Why is this useful?

### 1. You don‚Äôt just get an answer, you get a **decision process**

`POST /v1/decide` returns, following the Swagger `DecideResponse` schema:

- `chosen`
  - `action`: short description of **the one step to take now**
  - `rationale`: why that step was chosen
  - `uncertainty`: 0‚Äì1 uncertainty score
- `alternatives[]` (`Option`)
  - other candidate options that were considered
- `evidence[]` (`EvidenceItem`)
  - which pieces of evidence were used as justification
- `critique[]` / `debate[]`
  - internal self-critique and pseudo-debate views
- `telos_score`
  - alignment score against the current value / goal configuration
- `fuji` (`FujiDecision`)
  - safety / ethics gate result: `allow | modify | block | abstain`
- `trust_log`
  - immutable trust log entry with `sha256_prev` for chaining

> In other words: **‚ÄúWhy did it choose this action?‚Äù is always structured.**  
> This makes VERITAS suitable for AGI research, safety evaluation and audit workflows.

---

### 2. You can treat AGI-style tasks as **framework-level decisions**

The `Context` schema (from the Swagger definition) looks like this:

```yaml
Context:
  type: object
  required: [user_id, query]
  properties:
    user_id: {type: string}
    session_id: {type: string}
    query: {type: string, description: "User query / problem statement"}
    goals: {type: array, items: {type: string}}
    constraints: {type: array, items: {type: string}}
    time_horizon: {type: string, enum: ["short","mid","long"]}
    preferences: {type: object}
    tools_allowed: {type: array, items: {type: string}}
    telos_weights:
      type: object
      properties:
        W_Transcendence: {type: number}
        W_Struggle: {type: number}
    affect_hint: {type: string, enum: ["calm","focused","empathetic","concise"]}

For AGI-ish questions, you feed in:
	‚Ä¢	medium / long-term time_horizon
	‚Ä¢	value weights in telos_weights
	‚Ä¢	allowed tools in tools_allowed
	‚Ä¢	preferred response tone in affect_hint

So you can ask VERITAS to handle ‚Äúmeta-decisions for an AGI project‚Äù.

Example ‚Äì choose the shortest path to an MVP demo:

‚ÄúWhat is the fastest plan to ship a VERITAS AGI-framework MVP demo that a third party can understand?‚Äù

{
  "context": {
    "user_id": "fujishita",
    "session_id": "sess-agi-mvp-001",
    "query": "Fastest plan to ship a VERITAS AGI-framework MVP demo that third parties can understand",
    "goals": [
      "Build a demo that explains VERITAS in 10 minutes",
      "Clearly communicate the AGI framework skeleton"
    ],
    "constraints": [
      "Finish within this week",
      "Use only local environment + GitHub + Swagger Studio"
    ],
    "time_horizon": "short",
    "telos_weights": {
      "W_Transcendence": 0.6,
      "W_Struggle": 0.4
    },
    "affect_hint": "focused"
  },
  "options": [],
  "min_evidence": 2,
  "stream": false
}

/v1/decide will then:
	‚Ä¢	list candidate step sequences in alternatives[]
	‚Ä¢	pick the first step to execute this week in chosen.action
	‚Ä¢	expose quality & safety via telos_score and fuji.status

Effectively, it becomes a ‚Äúcommand API for AGI projects‚Äù.

‚∏ª

3. Safety gate, memory and trust are all exposed as APIs

The Swagger definition maps to the following endpoints
(all require an X-API-Key header):

GET /health
	‚Ä¢	Simple health check. Returns 200 if the server is up.

POST /v1/decide
	‚Ä¢	Full decision loop.
	‚Ä¢	Request body: context (as above) + optional options[] / min_evidence / stream
	‚Ä¢	Response: DecideResponse (chosen / alternatives / evidence / fuji / trust_log / ‚Ä¶)

POST /v1/fuji/validate
	‚Ä¢	Safety & ethics validation for a single action + context.

Example:

{
  "action": "Run the user-specified AGI experiment on production data",
  "context": {
    "user_id": "fujishita",
    "query": "Is this experiment safe to run?",
    "time_horizon": "mid"
  }
}

	‚Ä¢	Response: FujiDecision
	‚Ä¢	status: allow | modify | block | abstain
	‚Ä¢	reasons[], violations[]

POST /v1/memory/put
	‚Ä¢	Append to persistent memory:

{
  "user_id": "fujishita",
  "key": "veritas_agi_todos",
  "value": "Priority TODO list for the AGI MVP v1"
}

GET /v1/memory/get
	‚Ä¢	Retrieve value by user_id + key.

GET /v1/logs/trust/{request_id}
	‚Ä¢	Retrieve the immutable trust log created during /v1/decide.
	‚Ä¢	Because entries are chained via sha256_prev, you can track when, on what basis and who approved each decision.

‚∏ª

üåê Using OpenAPI / Swagger Studio

The OpenAPI schema (the YAML you paste into Swagger Studio) is:
	‚Ä¢	openapi: 3.1.0
	‚Ä¢	info.title: VERITAS Public API
	‚Ä¢	servers[0].url: http://127.0.0.1:8000
	‚Ä¢	securitySchemes.ApiKeyAuth:
	‚Ä¢	type: apiKey
	‚Ä¢	in: header
	‚Ä¢	name: X-API-Key

Typical flow in Swagger Studio / Editor:
	1.	Open Swagger Editor / Swagger Studio.
	2.	Paste the OpenAPI YAML into the left pane.
	3.	Confirm servers[0].url is http://127.0.0.1:8000.
	4.	Click Authorize, select ApiKeyAuth, and enter your X-API-Key.
	5.	Choose POST /v1/decide, click Try it out, and send a JSON payload like the AGI example above.

Your local uvicorn veritas_os.api.server:app responds, and the Editor shows a DecideResponse JSON matching the schema.

This gives you a ‚ÄúSwagger-driven Proto-AGI OS dev style‚Äù: experiment with decision loops live from the OpenAPI UI.

‚∏ª

üõ† Setup (assuming you pull veritas_clean_test2)

The veritas_os directory lives inside the veritas_clean_test2 repository.

0. Clone the repository

cd ~
git clone https://github.com/veritasfuji-japan/veritas_clean_test2.git
cd veritas_clean_test2

Project layout

veritas_os/
‚îú‚îÄ api/                      # Public API & dashboard
‚îÇ  ‚îú‚îÄ __init__.py
‚îÇ  ‚îú‚îÄ constants.py           # Shared constants
‚îÇ  ‚îú‚îÄ dashboard_server.py    # Simple server for Doctor Dashboard
‚îÇ  ‚îú‚îÄ evolver.py             # Future self-improvement API scaffold
‚îÇ  ‚îú‚îÄ merge_trust_logs.py    # Tool for merging trust logs
‚îÇ  ‚îú‚îÄ schemas.py             # FastAPI / Pydantic schemas
‚îÇ  ‚îú‚îÄ server.py              # Main API (/v1/decide, /v1/fuji, ‚Ä¶)
‚îÇ  ‚îî‚îÄ telos.py               # Telos (value weights) helpers
‚îÇ
‚îú‚îÄ core/                     # Central VERITAS logic (AGI skeleton)
‚îÇ  ‚îú‚îÄ __init__.py
‚îÇ  ‚îú‚îÄ models/
‚îÇ  ‚îÇ  ‚îú‚îÄ __init__.py
‚îÇ  ‚îÇ  ‚îî‚îÄ memory_model.pkl    # Embedding model for MemoryOS
‚îÇ  ‚îú‚îÄ adapt.py               # Self-adaptation logic (future use)
‚îÇ  ‚îú‚îÄ affect.py              # Tone / affect control
‚îÇ  ‚îú‚îÄ critique.py            # CritiqueOS: self-critique phase
‚îÇ  ‚îú‚îÄ debate.py              # DebateOS: multi-view pseudo-debate
‚îÇ  ‚îú‚îÄ evidence.py            # EvidenceOS: evidence retrieval & scoring
‚îÇ  ‚îú‚îÄ fuji.py                # FUJI Gate: safety / ethics decisions
‚îÇ  ‚îú‚îÄ identity.py            # System identity / meta-info
‚îÇ  ‚îú‚îÄ kernel.py              # Core kernel wiring all OS modules
‚îÇ  ‚îú‚îÄ llm_client.py          # OpenAI API wrapper
‚îÇ  ‚îú‚îÄ logging.py             # Logging utilities
‚îÇ  ‚îú‚îÄ memory.py              # MemoryOS: long-term memory manager
‚îÇ  ‚îú‚îÄ planner.py             # PlannerOS: step decomposition
‚îÇ  ‚îú‚îÄ reason.py              # ReasonOS: reasoning chains
‚îÇ  ‚îú‚îÄ reflection.py          # ReflectionOS: self-reflection
‚îÇ  ‚îú‚îÄ rsi.py                 # RSI / self-improvement notes (experimental)
‚îÇ  ‚îú‚îÄ sanitize.py            # Input/output sanitisation
‚îÇ  ‚îú‚îÄ strategy.py            # High-level strategy logic
‚îÇ  ‚îú‚îÄ tools.py               # Helper tools
‚îÇ  ‚îú‚îÄ value_core.py          # ValueCore: EMA / next_value_boost
‚îÇ  ‚îú‚îÄ world.py               # WorldOS: state update helpers
‚îÇ  ‚îú‚îÄ world_model.py         # WorldModel: world snapshots
‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ logging/               # Logging submodules
‚îÇ  ‚îÇ  ‚îú‚îÄ __init__.py
‚îÇ  ‚îÇ  ‚îú‚îÄ dataset_writer.py   # Export training data
‚îÇ  ‚îÇ  ‚îî‚îÄ paths.py            # Log path management
‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ memory/                # Vector store / search modules
‚îÇ     ‚îú‚îÄ __init__.py
‚îÇ     ‚îú‚îÄ embedder.py         # Embedding generator
‚îÇ     ‚îú‚îÄ engine.py           # Retrieval engine
‚îÇ     ‚îú‚îÄ episodic.index.npz  # Nearest-neighbour index
‚îÇ     ‚îú‚îÄ index_cosine.py     # Cosine similarity search
‚îÇ     ‚îî‚îÄ store.py            # Storage layer
‚îÇ
‚îú‚îÄ scripts/                  # CLI tools & ops scripts
‚îÇ  ‚îú‚îÄ alert_doctor.py        # Send Slack alerts from doctor_report
‚îÇ  ‚îú‚îÄ analyze_logs.py        # Summarise decision logs
‚îÇ  ‚îú‚îÄ auto_heal.sh           # Auto-recovery (experimental)
‚îÇ  ‚îú‚îÄ backup_logs.sh         # Zip backups of logs
‚îÇ  ‚îú‚îÄ decide.py              # CLI helper for /v1/decide
‚îÇ  ‚îú‚îÄ decide_plan.py         # Planning-focused decide wrapper
‚îÇ  ‚îú‚îÄ doctor.py              # Generate doctor_report.json
‚îÇ  ‚îú‚îÄ doctor.sh              # Run doctor ‚Üí report in one shot
‚îÇ  ‚îú‚îÄ generate_report.py     # Render HTML Doctor Dashboard
‚îÇ  ‚îú‚îÄ heal.sh                # Simple health check & repair
‚îÇ  ‚îú‚îÄ health_check.py        # API health check
‚îÇ  ‚îú‚îÄ memory_sync.py         # Sync memory.json
‚îÇ  ‚îú‚îÄ memory_train.py        # Retrain MemoryOS embeddings
‚îÇ  ‚îú‚îÄ notify_slack.py        # Slack notification helper
‚îÇ  ‚îú‚îÄ start_server.sh        # Start uvicorn server
‚îÇ  ‚îú‚îÄ sync_to_drive.sh       # Google Drive backup via rclone
‚îÇ  ‚îú‚îÄ veritas.sh             # Top-level CLI (full / decide / report ‚Ä¶)
‚îÇ  ‚îî‚îÄ veritas_monitor.sh     # Periodic monitoring / self-diagnosis loop
‚îÇ
‚îú‚îÄ templates/
‚îÇ  ‚îú‚îÄ personas/              # Agent persona templates
‚îÇ  ‚îú‚îÄ styles/                # Output style templates
‚îÇ  ‚îî‚îÄ tones/                 # Tone presets
‚îÇ
‚îú‚îÄ README.md                 # Japanese documentation
‚îú‚îÄ README_ENGLISH.md         # This file
‚îú‚îÄ requirements.txt          # Python dependencies
‚îî‚îÄ .gitignore

1. Create a Python virtual environment

cd ~/veritas_clean_test2

# If Python 3.11 is not installed:
brew install python@3.11

python3.11 -m venv .venv
source .venv/bin/activate

2. Install dependencies

cd ~/veritas_clean_test2/veritas_os
source ../.venv/bin/activate

export OPENAI_API_KEY="YOUR_OPENAI_API_KEY"

pip install --upgrade pip
pip install joblib
pip install requests
pip install matplotlib
pip install "openai>=1.0.0" scikit-learn

pip install -r requirements.txt

3. Use a separate data directory (recommended)

cd ~/veritas_clean_test2
export VERITAS_DATA_DIR=~/veritas_clean_test2/data
mkdir -p "$VERITAS_DATA_DIR"

All runtime artefacts (e.g. trust_log.json, world_state.json, memory snapshots) will be written under this directory.

‚∏ª

4. Start the API server

cd ~/veritas_clean_test2
source .venv/bin/activate

python3 -m uvicorn veritas_os.api.server:app --reload --port 8000

‚Ä¢	Confirm that http://127.0.0.1:8000 matches the servers[0].url in your OpenAPI schema.
	‚Ä¢	When you see Application startup complete. in the logs, the server is ready.

‚∏ª

ü©∫ Generating the Doctor Dashboard

To create a self-diagnostic HTML report from logs:

cd ~/veritas_clean_test2/veritas_os/scripts
source ../.venv/bin/activate

python generate_report.py

Outputs:
	‚Ä¢	scripts/logs/doctor_report.json
	‚Ä¢	scripts/logs/doctor_dashboard.html

The dashboard visualises:
	‚Ä¢	daily count of decisions
	‚Ä¢	FUJI status distribution
	‚Ä¢	latency trends
	‚Ä¢	number of memory evidences used
	‚Ä¢	Value EMA over time
	‚Ä¢	redaction / modification frequency
	‚Ä¢	memory hit-rate

These internal metrics are not visible in a single DecideResponse, but are crucial for monitoring and research.

‚∏ª

‚úÖ Verified runtime environment

This configuration has been tested with:
	‚Ä¢	macOS
	‚Ä¢	Python 3.11.14
	‚Ä¢	veritas_clean_test2 cloned from GitHub
	‚Ä¢	python3.11 -m venv .venv ‚Üí pip install -r requirements.txt
	‚Ä¢	python3 -m uvicorn veritas_os.api.server:app --reload --port 8000
	‚Ä¢	OpenAPI 3.1 schema pasted into Swagger Studio / Editor
	‚Ä¢	After setting X-API-Key, POST /v1/decide successfully handled AGI-style queries
and returned valid DecideResponse objects (as of 2025-11-15).

‚∏ª

In one sentence
	‚Ä¢	VERITAS OS exposes LLMs as a public HTTP API for AGI-style decision-making,
	‚Ä¢	when paired with Swagger Studio + OpenAPI 3.1, it enables:
	‚Ä¢	reproducible experiments,
	‚Ä¢	auditable trust logs,
	‚Ä¢	safety-gated decision loops,

all accessible over a clean REST interface.

‚∏ª

For researchers

This repository is intended as a local, reproducible playground for AGI / AI Safety / AI Alignment work:
	‚Ä¢	experimenting with a ‚ÄúDecision OS‚Äù architecture,
	‚Ä¢	evaluating safety of LLM-based agents, and
	‚Ä¢	analysing the behaviour of agents with long-term memory + chained trust logs.

Pull it, spin it up, and treat /v1/decide as the control panel for your proto-AGI experiments.

Copyright (c) 2025 Takeshi Fujishita
All rights reserved.
