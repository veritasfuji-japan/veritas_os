# veritas/core/value_core.py
from __future__ import annotations

import json
import logging
import os
import re
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Any

logger = logging.getLogger(__name__)

# OS åˆ¤å®šï¼ˆWindowsäº’æ›æ€§ã®ãŸã‚ï¼‰
IS_WIN = os.name == "nt"

if not IS_WIN:
    try:
        import fcntl  # type: ignore
    except ImportError:
        fcntl = None  # type: ignore
else:
    fcntl = None  # type: ignore

# å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from .utils import _to_float, _clip01


def _clean_text(x: str) -> str:
    # æ•°å­—ãƒ»å°æ•°ãƒ»æŒ‡æ•°è¡¨ç¾ï¼ˆe-33 ãªã©ï¼‰ã‚’é™¤å»
    x = re.sub(r"[0-9]+(?:\.[0-9]+)?(?:e[-+]?[0-9]+)?", "", x)
    return x


def _normalize_weights(w: Dict[str, Any]) -> Dict[str, float]:
    """
    å…¥åŠ›ã•ã‚ŒãŸ weight ã‚’ 0..1 ã«ã‚¯ãƒªãƒƒãƒ—ã—ã€æœ€å¤§å€¤ãŒ1ã‚’è¶…ãˆã‚‹å ´åˆã¯ 1 ã«åˆã‚ã›ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã€‚
    ç©ºãªã‚‰ DEFAULT_WEIGHTS ã‚’è¿”ã™ã€‚
    """
    if not w:
        return DEFAULT_WEIGHTS.copy()
    # ã¾ãš 0..1 ã«åã‚ã‚‹
    w2 = {k: _clip01(_to_float(v, 0.0)) for k, v in w.items()}
    mx = max(w2.values()) if w2 else 1.0
    if mx > 1.0 + 1e-9:  # å¿µã®ãŸã‚
        w2 = {k: (v / mx) for k, v in w2.items()}
    return w2


# ==============================
#   è¨­å®šãƒ»ä¿å­˜ãƒ‘ã‚¹
# ==============================
CFG_DIR = Path(os.path.expanduser("~/.veritas"))
CFG_PATH = CFG_DIR / "value_core.json"
TRUST_LOG_PATH = Path(os.path.expanduser("~/.veritas/trust_log.jsonl"))

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ä¾¡å€¤é‡ã¿ï¼ˆ0.0ã€œ1.0ï¼‰
DEFAULT_WEIGHTS: Dict[str, float] = {
    "ethics": 0.95,        # å€«ç†
    "legality": 0.95,      # åˆæ³•æ€§
    "harm_avoid": 0.95,    # éåŠ å®³
    "truthfulness": 0.85,  # çœŸå®Ÿæ€§ï¼æ¤œè¨¼å¯èƒ½æ€§
    "user_benefit": 0.85,  # åˆ©ç›Šãƒ»ä¾¿ç›Š
    "reversibility": 0.70, # å¯é€†æ€§
    "accountability": 0.70,# èª¬æ˜è²¬ä»»
    "efficiency": 0.60,    # åŠ¹ç‡ãƒ»ã‚³ã‚¹ãƒˆ
    "autonomy": 0.60,      # è‡ªå¾‹æ€§
    # â†“æ—¥æœ¬èªã‚­ãƒ¼ï¼ˆè¡Œå‹•æ–¹é‡ï¼‰
    "æœ€å°ã‚¹ãƒ†ãƒƒãƒ—ã§å‰é€²ã™ã‚‹": 0.60,
    "mvpã‚³ãƒ¼ãƒ‰ã‚’é€²ã‚ã‚‹": 0.60,
    "ä¸€æ¬¡æƒ…å ±(å…¬å¼/è«–æ–‡)ã‚’èª¿ã¹ã‚‹": 0.70,
    "æƒ…å ±åé›†ã‚’å„ªå…ˆã™ã‚‹": 0.60,
    "ã‚µã‚¦ãƒŠæ§ã‚": 0.30,
}

# ==============================
#   ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå­¦ç¿’ã™ã‚‹ä¾¡å€¤è¦³ï¼‰
# ==============================
@dataclass
class ValueProfile:
    weights: Dict[str, float]

    # ---- èª­ã¿è¾¼ã¿ ----
    @classmethod
    def load(cls) -> "ValueProfile":
        """
        ~/.veritas/value_core.json ã‚’èª­ã¿è¾¼ã‚€ã€‚
        ãªã‘ã‚Œã° DEFAULT_WEIGHTS ã‚’åˆæœŸå€¤ã¨ã—ã¦ä¿å­˜ã—ã¦ã‹ã‚‰è¿”ã™ã€‚
        """
        try:
            CFG_DIR.mkdir(parents=True, exist_ok=True)
            if CFG_PATH.exists():
                with CFG_PATH.open("r", encoding="utf-8") as f:
                    data = json.load(f)

                # {"weights": {...}} å½¢å¼ or ãã®ã¾ã¾ dict ã®ä¸¡æ–¹ã«å¯¾å¿œ
                if isinstance(data, dict):
                    loaded = data.get("weights", data)
                else:
                    loaded = {}

                merged = DEFAULT_WEIGHTS.copy()
                merged.update(
                    {
                        k: _clip01(_to_float(v, merged.get(k, 0.0)))
                        for k, v in (loaded or {}).items()
                    }
                )
                return cls(weights=_normalize_weights(merged))
        except Exception as e:
            logger.warning("load failed: %s", e)

        # å¤±æ•—ã—ãŸã‚‰ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ä½œã‚Šç›´ã—
        prof = cls(weights=DEFAULT_WEIGHTS.copy())
        prof.save()
        return prof

    # ---- ä¿å­˜ ----
    def save(self) -> None:
        CFG_DIR.mkdir(parents=True, exist_ok=True)
        data = {"weights": _normalize_weights(self.weights)}
        with CFG_PATH.open("w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    # ---- ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ ----
    def update_from_scores(self, scores: Dict[str, float], lr: float = 0.02) -> None:
        """
        ç›´è¿‘ã® Value scores ã‹ã‚‰ weights ã‚’å°‘ã—ã ã‘æ›´æ–°ã™ã‚‹ã€‚
        w_new = (1 - lr) * w_old + lr * score
        """
        w = dict(self.weights)
        for k, s in scores.items():
            old = float(w.get(k, DEFAULT_WEIGHTS.get(k, 0.5)))
            w[k] = _clip01((1.0 - lr) * old + lr * float(s))

        self.weights = _normalize_weights(w)
        self.save()


# ==============================
#   è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
# ==============================
@dataclass
class ValueResult:
    scores: Dict[str, float]
    total: float
    top_factors: List[str]
    rationale: str


# ==============================
#   ç°¡æ˜“ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ã‚¯ã‚¹
# ==============================
NEG_WORDS = {"é•æ³•", "çŠ¯ç½ª", "å€‹äººæƒ…å ±ã®æ™’ã—", "æš´åŠ›", "æ­¦å™¨", "å·®åˆ¥", "èª¹è¬—ä¸­å‚·"}
RISKY_WORDS = {"æŠ•æ©Ÿ", "ã‚®ãƒ£ãƒ³ãƒ–ãƒ«", "æå¤±", "ãƒãƒƒã‚­ãƒ³ã‚°", "éåº¦ã®è‡ªå‹•åŒ–"}


def heuristic_value_scores(q: str, ctx: dict) -> Dict[str, float]:
    qn = (q or "").lower()

    # åˆæœŸå€¤ã‚’ DEFAULT_WEIGHTS ã‹ã‚‰ä½œã‚‹
    s = {k: float(DEFAULT_WEIGHTS.get(k, 0.5)) for k in DEFAULT_WEIGHTS}

    # ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ¯ãƒ¼ãƒ‰
    if any(w in qn for w in NEG_WORDS):
        s["ethics"] = 0.0
        s["legality"] = 0.0
        s["harm_avoid"] = 0.0

    # ãƒªã‚¹ã‚¯ãƒ¯ãƒ¼ãƒ‰
    if any(w in qn for w in RISKY_WORDS):
        s["reversibility"] = 0.4
        s["efficiency"] = 0.5

    # ãƒã‚¸ãƒ†ã‚£ãƒ–ãªãƒ¯ãƒ¼ãƒ‰
    if "å ±å‘Š" in q or "èª¬æ˜" in q or "å¼•ç”¨" in q or "æ¤œè¨¼" in q:
        s["truthfulness"] = 0.95
        s["accountability"] = 0.9

    if "è‡ªå‹•" in q or "è‡ªå¾‹" in q:
        s["autonomy"] = 0.8

    if "å®‰å…¨" in q or "å±é™º" in q or "ãƒªã‚¹ã‚¯" in q:
        s["harm_avoid"] = min(s["harm_avoid"], 0.85)

    if "æ”¹å–„" in q or "æœ€é©" in q or "çŸ­ç¸®" in q:
        s["efficiency"] = 0.9
        s["accountability"] = 0.8

    return {k: _clip01(v) for k, v in s.items()}


# ==============================
#   ãƒ¡ã‚¤ãƒ³è©•ä¾¡é–¢æ•°ï¼ˆå­¦ç¿’ä»˜ãï¼‰
# ==============================
def evaluate(query: str, context: Dict[str, Any]) -> ValueResult:
    """
    - heuristic_value_scores ã§ scores ã‚’å‡ºã™
    - context["value_scores"] / ["value_weights"] ã§ä¸Šæ›¸ãå¯èƒ½
    - ValueProfile ã‚’ä½¿ã£ã¦ total ã‚’è¨ˆç®—
    - ã¤ã„ã§ã« weights ã‚’å°‘ã—ã ã‘å­¦ç¿’ã—ã¦ä¿å­˜
    """
    ctx = context or {}
    q = query or ""
    qn = q.lower()

    # 1) ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ã‚¯ã‚¹ã§åŸºæœ¬ã‚¹ã‚³ã‚¢
    scores = heuristic_value_scores(q, ctx)

    # 2) context ã‹ã‚‰ã®ã‚¹ã‚³ã‚¢ä¸Šæ›¸ãï¼ˆã‚ã‚Œã°å„ªå…ˆï¼‰
    ctx_scores_raw: Dict[str, Any] = ctx.get("value_scores", {}) or {}
    for k, v in ctx_scores_raw.items():
        scores[k] = _clip01(_to_float(v, scores.get(k, 0.0)))

    # 3) è¡Œå‹•ç³»ï¼ˆæ—¥æœ¬èªã‚­ãƒ¼ï¼‰ãƒ’ãƒ³ãƒˆ
    def _hint(tf: bool, base: float) -> float:
        return _clip01(base if tf else scores.get("æœ€å°ã‚¹ãƒ†ãƒƒãƒ—ã§å‰é€²ã™ã‚‹", 0.0))

    scores.setdefault("æœ€å°ã‚¹ãƒ†ãƒƒãƒ—ã§å‰é€²ã™ã‚‹", _hint(True, 0.7))
    scores.setdefault("mvpã‚³ãƒ¼ãƒ‰ã‚’é€²ã‚ã‚‹", _clip01(0.6 if ("code" in qn or "å®Ÿè£…" in qn) else 0.3))
    scores.setdefault(
        "ä¸€æ¬¡æƒ…å ±(å…¬å¼/è«–æ–‡)ã‚’èª¿ã¹ã‚‹",
        _clip01(0.6 if ("è«–æ–‡" in qn or "paper" in qn or "rfc" in qn) else 0.3),
    )
    scores.setdefault(
        "æƒ…å ±åé›†ã‚’å„ªå…ˆã™ã‚‹",
        _clip01(0.5 if ("èª¿æŸ»" in qn or "ãƒªã‚µãƒ¼ãƒ" in qn) else 0.3),
    )
    scores.setdefault("ã‚µã‚¦ãƒŠæ§ã‚", _clip01(scores.get("ã‚µã‚¦ãƒŠæ§ã‚", 0.3)))

    # 4) é‡ã¿ã®æ±ºå®šï¼ˆä¿å­˜ > context ä¸Šæ›¸ãï¼‰
    prof = ValueProfile.load()
    merged_w = prof.weights.copy()
    ctx_weights = ctx.get("value_weights", {}) or {}
    for k, v in ctx_weights.items():
        merged_w[k] = _clip01(_to_float(v, merged_w.get(k, 0.0)))
    weights = _normalize_weights(merged_w)

    # 5) åŠ é‡å¹³å‡ã§ totalï¼ˆsumâ†’ã‚¯ãƒªãƒƒãƒ—ã§ã¯ãªãå¹³å‡ã«ã™ã‚‹ã®ã§ 1.0 å›ºå®šã‚’é˜²ãï¼‰
    if scores:
        contribs = {
            k: float(scores[k]) * float(weights.get(k, 1.0))
            for k in scores.keys()
        }
        total_raw = sum(contribs.values()) / max(len(contribs), 1)
    else:
        total_raw = 0.5
    total = _clip01(total_raw)

    # 6) ä¸Šä½è¦ç´ ï¼ˆweight * score ã§ã‚½ãƒ¼ãƒˆï¼‰
    factors_sorted = sorted(
        scores.items(),
        key=lambda kv: float(kv[1]) * float(weights.get(kv[0], 1.0)),
        reverse=True,
    )
    top = [k for k, _ in factors_sorted[:5]]

    # 7) ç°¡å˜ãª rationale
    rationale_parts: List[str] = []
    if "ethics" in top:
        rationale_parts.append("å€«ç†é¢ã‚’é‡è¦–ã—ã¾ã—ãŸ")
    if "legality" in top:
        rationale_parts.append("æ³•çš„ãªå®‰å…¨æ€§ã‚’è€ƒæ…®ã—ã¾ã—ãŸ")
    if "user_benefit" in top:
        rationale_parts.append("ã‚ãªãŸã®é•·æœŸçš„ãªåˆ©ç›Šã‚’å„ªå…ˆã—ã¾ã—ãŸ")
    if not rationale_parts:
        rationale_parts.append("å…¨ä½“ã®ãƒãƒ©ãƒ³ã‚¹ã‚’è¦‹ã¦åˆ¤æ–­ã—ã¾ã—ãŸ")
    rationale = " / ".join(rationale_parts)

    # 8) ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ï¼ˆç¦æ­¢ãƒ•ãƒ©ã‚°ãŒç«‹ã£ã¦ã„ãªã‘ã‚Œã°ï¼‰
    if not ctx.get("no_learn_values", False):
        lr = float(ctx.get("value_lr", 0.02))
        prof.update_from_scores(scores, lr=lr)

    return ValueResult(scores=scores, total=total, top_factors=top, rationale=rationale)


# ==============================
#   å¤–éƒ¨APIã‹ã‚‰ã®é‡ã¿æ›´æ–°
# ==============================
def update_weights(new_weights: Dict[str, Any]) -> Dict[str, float]:
    prof = ValueProfile.load()
    for k, v in (new_weights or {}).items():
        prof.weights[k] = _clip01(_to_float(v, prof.weights.get(k, 0.0)))
    prof.weights = _normalize_weights(prof.weights)
    prof.save()
    return prof.weights


# ==============================
#   ğŸ” Meta-Learning: ä¿¡é ¼ãƒ­ã‚°ã‹ã‚‰è‡ªå·±é©å¿œ
# ==============================
def rebalance_from_trust_log(log_path: str = str(TRUST_LOG_PATH)) -> None:
    """trust_log.jsonl ã®å†…å®¹ã‹ã‚‰ ValueCore ã‚’è‡ªå‹•èª¿æ•´"""
    log_file = Path(log_path)
    if not log_file.exists():
        logger.warning("trust_log.jsonl not found")
        return

    scores: List[float] = []
    with log_file.open("r", encoding="utf-8") as f:
        for line in f:
            try:
                j = json.loads(line)
                if "score" in j:
                    scores.append(float(j["score"]))
            except Exception:
                continue

    if not scores:
        logger.warning("No scores found in trust log.")
        return

    # --- EMA ---
    ema, alpha = 0.0, 0.2
    for v in scores:
        ema = alpha * v + (1.0 - alpha) * ema
    logger.info("Trust EMA: %.3f", ema)

    prof = ValueProfile.load()
    w = prof.weights.copy()

    # --- è‡ªå·±é©å¿œãƒ­ã‚¸ãƒƒã‚¯ï¼ˆä¾‹ï¼‰ ---
    if ema < 0.7:
        w["truthfulness"] = _clip01(_to_float(w.get("truthfulness", 0.8)) + 0.05)
        w["accountability"] = _clip01(_to_float(w.get("accountability", 0.7)) + 0.05)
    elif ema > 0.9:
        w["efficiency"] = _clip01(_to_float(w.get("efficiency", 0.6)) + 0.05)

    prof.weights = _normalize_weights(w)
    prof.save()
    logger.info("ValueCore rebalanced successfully at %s", time.strftime('%Y-%m-%d %H:%M:%S'))

    # ==============================
#   Trust Log ã¸ã®1è¡Œè¿½è¨˜
# ==============================
def append_trust_log(
    user_id: str,
    score: float,
    note: str = "",
    source: str = "manual",
    extra: Dict[str, Any] | None = None,
) -> None:
    """
    trust_log.jsonl ã« 1 è¡Œè¿½è¨˜ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã€‚
    - score: 0.0ã€œ1.0 ã‚’æƒ³å®šï¼ˆç¯„å›²å¤–ãªã‚‰ã‚¯ãƒªãƒƒãƒ—ï¼‰
    - note : ç°¡å˜ãªãƒ¡ãƒ¢ï¼ˆã€Œä»Šæ—¥ã®æ±ºå®šã¯ã‹ãªã‚Šè‰¯ã„ã€ãªã©ï¼‰
    - source: "manual" / "auto" ãªã©
    """
    try:
        log_file = TRUST_LOG_PATH
        log_file.parent.mkdir(parents=True, exist_ok=True)

        s = _clip01(score)
        rec = {
            "ts": time.strftime("%Y-%m-%d %H:%M:%S"),
            "user_id": user_id,
            "score": s,
            "note": note,
            "source": source,
        }
        if extra:
            rec["extra"] = extra

        with log_file.open("a", encoding="utf-8") as f:
            if fcntl is not None:
                fcntl.flock(f.fileno(), fcntl.LOCK_EX)
            try:
                f.write(json.dumps(rec, ensure_ascii=False) + "\n")
                f.flush()
            finally:
                if fcntl is not None:
                    fcntl.flock(f.fileno(), fcntl.LOCK_UN)

        logger.debug("trust_log appended: user=%s, score=%s", user_id, s)
    except Exception as e:
        logger.warning("append_trust_log failed: %s", e)
